{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset mfaq (C:/Users/Adam/.cache/huggingface/datasets/clips___mfaq/de_flat/1.1.0/046d91e0a0390af15e8521190b906d67fd3d4440839559764d1659f48a8dbe7c)\n",
      "100%|██████████| 2/2 [00:00<00:00,  3.25it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import scipy as sklearn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import rc\n",
    "from io import StringIO\n",
    "from html.parser import HTMLParser\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim \n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "PRE_TRAINED_MODEL_NAME = 'deepset/gbert-base'\n",
    "qna_data = pd.read_csv('../data/faq_info_labels.csv')\n",
    "mfaq = load_dataset(\"clips/mfaq\", \"de_flat\")\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.text = StringIO()\n",
    "    def handle_data(self, d):\n",
    "        self.text.write(d)\n",
    "    def get_data(self):\n",
    "        return self.text.getvalue()\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "half_len = int(len(qna_data)/2)\n",
    "data_matches = qna_data.iloc[:half_len,:]\n",
    "data_distinct = qna_data.iloc[half_len:,:]\n",
    "\n",
    "data_distinct = data_distinct.reset_index(drop=True)\n",
    "print(data_distinct)\n",
    "df1 = data_distinct.iloc[np.random.permutation(data_distinct.index)].reset_index(drop=True)\n",
    "data_distinct['answer'] = df1['answer']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "data_distinct['matching'] = 0\n",
    "data_matches['matching'] = 1\n",
    "\n",
    "df = pd.concat([data_matches,data_distinct])\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.to_csv('../data/faq_info_labels.csv', index=None, header=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "\n",
    "q_token_lens = []\n",
    "a_token_lens = []\n",
    "for txt in df['question']:\n",
    "    #print(txt)\n",
    "    tokens = tokenizer.encode(txt, max_length=160, truncation=True)\n",
    "    q_token_lens.append(len(tokens))\n",
    "for txt in df['answer']:\n",
    "    #print(txt)\n",
    "    tokens = tokenizer.encode(txt, max_length=1024, truncation=True)\n",
    "    a_token_lens.append(len(tokens))\n",
    "#sns.distplot(q_token_lens)\n",
    "#sns.distplot(a_token_lens)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QnADataset(Dataset):\n",
    "    def __init__(self, question, answer, targets, tokenizer, max_length):\n",
    "        self.question = question\n",
    "        self.answer = answer\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = int(max_length)\n",
    "        self.doc_stride = 128 # The authorized overlap between two part of the context when splitting it is needed.\n",
    "        #self.q_len = int(q_len)\n",
    "        #self.a_len = int(a_len)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.answer)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        question = str(self.question[item])\n",
    "        context = str(self.answer[item])\n",
    "        target = self.targets[item]\n",
    "        \n",
    "        encoding = tokenizer(\n",
    "            question,\n",
    "            context,\n",
    "            max_length = self.max_length,\n",
    "            add_special_tokens = True,\n",
    "            padding='max_length',\n",
    "            truncation='only_second',\n",
    "            return_attention_mask = True,\n",
    "            return_token_type_ids = False,\n",
    "            return_tensors = 'pt',\n",
    "            #return_overflowing_tokens=True,\n",
    "            #return_offsets_mapping=True,\n",
    "            #stride=self.doc_stride\n",
    "        )\n",
    "        return {\n",
    "            'question_text': question,\n",
    "            'answer_text': context,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'targets': torch.tensor(target, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_text': 'Ist es sinnvoll, dass sich Mitarbeiterinnen und Mitarbeiter, die in einem medizinischen Bereich arbeiten, regelmäßig testen lassen? ',\n",
       " 'answer_text': 'Mit präventiven Reihentests in Krankenhäusern und Pflegeheimen und durch das Testen von Kontaktpersonen von Infizierten lassen sich Infektionsketten schnell erkennen und können besser unterbrochen werden. Die Nationale Teststrategie sieht vor, dass auch Personal in Krankenhäusern, Rehabilitationseinrichtungen und stationären und ambulanten Pflegeeinrichtungen vermehrt getestet werden. Als Kontaktpersonen sind Mitarbeiter, die COVID-19-Patienten betreuen, in jedem Falle regelmäßig zu testen. Bei Ausbrüchen in stationären Einrichtungen sollte auch das gesamte Personal einer Testung unterzogen werden. Auch regelmäßige Testungen im Rahmen z. B. von betriebsärztlichen Untersuchungen sind möglich. Außerdem kann das gesamte Personal, insbesondere in Gebieten mit erhöhten Infektionszahlen oder in der Betreuung von besonders vulnerablen Gruppen, regelmäßig getestet werden. Weitere Informationen finden Sie hier.',\n",
       " 'input_ids': tensor([ 102, 2302,  288,  ...,    0,    0,    0]),\n",
       " 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       " 'targets': tensor(1)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = QnADataset(\n",
    "        question=qna_data.question.to_numpy(),\n",
    "        answer=qna_data.answer.to_numpy(),\n",
    "        targets=qna_data.matching.to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=1024\n",
    "    )\n",
    "a.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train, df_test = train_test_split(\n",
    "  qna_data,\n",
    "  test_size=0.1,\n",
    "  random_state=RANDOM_SEED\n",
    ")\n",
    "df_val, df_test = train_test_split(\n",
    "  df_test,\n",
    "  test_size=0.5,\n",
    "  random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_length, batch_size):\n",
    "    ds = QnADataset(\n",
    "        question=df.question.to_numpy(),\n",
    "        answer=df.answer.to_numpy(),\n",
    "        targets=df.matching.to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=max_length\n",
    "    )\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size = batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "MAX_LEN = 512\n",
    "\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = next(iter(train_data_loader))\n",
    "example.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QnAClassifier(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(QnAClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, pooled_output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=False\n",
    "        )\n",
    "        output = self.drop(pooled_output)\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['nomatch', 'match']\n",
    "model = QnAClassifier(len(class_names))\n",
    "model = model.to(device)\n",
    "input_ids = example['input_ids'].to(device)\n",
    "attention_mask = example['attention_mask'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model,\n",
    "    data_loader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    scheduler,\n",
    "    n_examples\n",
    "):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    for d in data_loader:\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        targets = d[\"targets\"].to(device)\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "            losses.append(loss.item())\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_data_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(df_train)\n",
    "    )\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_data_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(df_val)\n",
    "    )\n",
    "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "        best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QnAClassifier(len(class_names))\n",
    "model.load_state_dict(torch.load('best_model_state.bin'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc, _ = eval_model(\n",
    "  model,\n",
    "  test_data_loader,\n",
    "  loss_fn,\n",
    "  device,\n",
    "  len(df_test)\n",
    ")\n",
    "test_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader):\n",
    "  model = model.eval()\n",
    "  questions = []\n",
    "  answers = []\n",
    "  predictions = []\n",
    "  prediction_probs = []\n",
    "  real_values = []\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "      question_text = d[\"question_text\"]\n",
    "      answer_text = d[\"answer_text\"]\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "      questions.extend(question_text)\n",
    "      answers.extend(answer_text)\n",
    "      predictions.extend(preds)\n",
    "      prediction_probs.extend(outputs)\n",
    "      real_values.extend(targets)\n",
    "  predictions = torch.stack(predictions).cpu()\n",
    "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
    "  real_values = torch.stack(real_values).cpu()\n",
    "  return questions, answers, predictions, prediction_probs, real_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_questions, y_answers, y_pred, y_pred_probs, y_test = get_predictions(\n",
    "  model,\n",
    "  test_data_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_question = \"Hat der Indego einen Regensensor?\"\n",
    "sample_answer = \"Nein, er kann aber auch bei leichtem (Niesel-)Regen mähen. Wir empfehlen allerdings, den Mäher nicht bei Regen arbeiten zu lassen, da dabei generell die Schnittqualität leidet bzw. Mäher und vor allem das Mähwerk stets stark verschmutzt werden. Mit der Betriebsart Smart Mow wird der Indego in die Lage versetzt, die optimale Zeit für das Schneiden deines Rasen automatisch zu planen, um Mähen bei Regen zu vermeiden.\"\n",
    "sample_matching = 1\n",
    "encoded_qna_pair = tokenizer.encode_plus(\n",
    "  sample_question,\n",
    "  sample_answer,\n",
    "  max_length=MAX_LEN,\n",
    "  add_special_tokens=True,\n",
    "  return_token_type_ids=False,\n",
    "  pad_to_max_length=True,\n",
    "  return_attention_mask=True,\n",
    "  return_tensors='pt',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = encoded_qna_pair['input_ids'].to(device)\n",
    "attention_mask = encoded_qna_pair['attention_mask'].to(device)\n",
    "output = model(input_ids, attention_mask)\n",
    "_, prediction = torch.max(output, dim=1)\n",
    "print(f'Question: {sample_question}')\n",
    "print(f'Answer: {sample_answer}')\n",
    "print(f'Matching  : {class_names[prediction]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mfaq = mfaq.data['validation']\n",
    "df_mfaq.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mfaq_q = pd.DataFrame.from_dict(df_mfaq['question'])\n",
    "df_mfaq_a = pd.DataFrame.from_dict(df_mfaq['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mfaq_a = df_mfaq_a.rename(columns={0: \"answer\"})\n",
    "df_mfaq_q = df_mfaq_q.rename(columns={0: \"question\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_mfaq_q, df_mfaq_a]\n",
    "df_mfaq = pd.concat(frames,axis=1, join=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mfaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_len = int(len(df_mfaq)/2)\n",
    "data_matches = df_mfaq.iloc[:half_len,:]\n",
    "data_distinct = df_mfaq.iloc[half_len:,:]\n",
    "\n",
    "data_distinct = data_distinct.reset_index(drop=True)\n",
    "df1 = data_distinct.iloc[np.random.permutation(data_distinct.index)].reset_index(drop=True)\n",
    "data_distinct['answer'] = df1['answer']\n",
    "data_distinct['matching'] = 0\n",
    "data_matches['matching'] = 1\n",
    "\n",
    "df_mfaq = pd.concat([data_matches,data_distinct])\n",
    "df_mfaq = df_mfaq.sample(frac=1).reset_index(drop=True)\n",
    "#df.to_csv('../data/faq_info_labels.csv', index=None, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mfaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfaq_dl = create_data_loader(df_mfaq, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "y_questions, y_answers, y_pred, y_pred_probs, y_test = get_predictions(\n",
    "  model,\n",
    "  mfaq_dl\n",
    ")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2931d21d056fbb417b13f70515e99f7cc9c60ee7d73a572131b198d23e9dd3a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
